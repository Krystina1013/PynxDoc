# 概述
为了使数据传输最小化，区块数据被分成了四个部分
1. 区块头：这个与原有的区块头的内容一致
2. 区块体：这个区块体包括三个部分（区块头、交易列表和post_csa_action),其中区块头和交易列表与原有的方案一致，而post_csa_action是需要跨分片处理项目，以目标为分组后的项目列表的哈希，即`Vec<target,hash(Vec<CSActionItem>)>`。在区块体里记录了哈希值，而哈希对应的实际内容并不包含在区块体中，而是放在附加数据中。
3. 附加数据：附加数据就是2中的`hash(Vec<CsaActiomItem>)`中的`Vec<CsaActiomItem>`对应的数据项，之所以不放在区块体中，区块需要在不同类型的链中传播，而有些链并不关心与自己不相干的`CsaActiomItem>`的数据，为了降低数据的传播量，我们使用附加数据的模式，附加数据只有在对方节点需要的时候发送命令，才会进行传输入。
4. 跨分片数据：与附加数据可以直接向对方节点请求获就可以得到数据不同，跨分片数据只能通过P2P存储系统获得，这个在分片数据的图上可以看到，就是通过中继处理的跨分片最终的数据。

## 实现
为了统一处理，我们从Core层向FRAME层提供统一按需存入和读取数据的特征：
```rust
pub trait OnDemandStorage {
    async fn put(data:Vec<u8>,additionTag:Option<&str>)->Result<Vec<u8>,Error>;
    async fn get(hash:Vec<u8>,additionTag:Option<&str>)->Result<Vec<u8>,Error>;
}
```
这个存储是两层结构的，第一层是一个最长时间不用的LRUCache对象，用于存储临时的数据，第二层是主动P2P存储网络，是一个可以相对长久存储数据，并且可以被全网任何一个节点读取的数据存储网络。

additionTag是一个标识值，标识该数据是附加数据还是跨分片数据。如果additionTag值是Some(value)，则是一个附加数据，而value的值就是ChainId+BlockNum;如果additionTag值是None，则表明是一个跨分片数据。

如果是跨分片数据，将被存入到P2P网络，如果是附加数据，既存入LruCache对象，也存入P2P存储网络。

### 数据存入
1. 当数据存入时，首先存入P2P存储网络，然后获得一个哈希值；
2. 如果是附加数据, 然后在LRUCache对象中存入这个<哈希,数据>对
3. 将哈希值返回。   
** 此处使用了P2P存储网络的哈希值，其原因是因为在目前的使用中，P2P网络和我们的哈希算法不一致，为了避免多建一层对应关系，直接使用P2P网络中产生的哈希。 ** 

### 数据读取
1. 如果additionTag是Some(value),则通过protocol向对端读取数据,如果读取成功，进入步骤3
    1. 对端是根据Some(value)中的value值，从取出对方的peerId，然后直接向该peerId发送命令获取数据
2. 根据哈希向P2P网络请求数据，如果成功，进入步骤3
3. 返回对应的数据



## 区块汇报和节点缓存
由上述可知，附加数据首先向某个对端请求，如果请求不成功，那么再向P2P网络请求。这个对端在哪里呢？其实是在收到某个节点发布的区块消息时，记录了该区块和节点的对应关系信息（ChainId/Number和对应的PeerId)。 当处理get请求时，从记录的列表中获取对应的peerId，然后再向对应的PeerId发送消请求。  
因此，在收到区块传播消息时，更新区块和节点的对应关系信息，是由数据按需读取的实现代码进行的。

## 定义和实现分离
显然，定义可以放在primitive/core里面，而由于实现与网络传输密切相关，放在client/network中是合理的。
